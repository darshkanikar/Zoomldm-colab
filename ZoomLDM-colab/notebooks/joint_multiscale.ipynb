{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# ✅ SETUP FOR GOOGLE COLAB\n",
    "# =============================\n",
    "!pip install --upgrade pip\n",
    "!pip install torch torchvision einops omegaconf huggingface_hub tqdm pillow matplotlib\n",
    "!pip install git+https://github.com/cvlab-stonybrook/ZoomLDM.git\n",
    "\n",
    "# =============================\n",
    "# ✅ IMPORTS\n",
    "# =============================\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from huggingface_hub import hf_hub_download\n",
    "from IPython.utils import io\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "from utils import collate_fn\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from large_image_gen.resizer import Resizer\n",
    "from large_image_gen.utils import model_pred, decode_large_image\n",
    "from large_image_gen.postprocess import postprocess_image\n",
    "\n",
    "# =============================\n",
    "# ✅ DEVICE (Colab-safe)\n",
    "# =============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# =============================\n",
    "# ✅ LOAD DATASET\n",
    "# =============================\n",
    "MAG = \"5x\"  # The sample dataset has 20x, 10x, 5x, 2_5x and 1_25x data\n",
    "ds = load_dataset(\"StonyBrook-CVLab/ZoomLDM-demo-dataset\", name=MAG, trust_remote_code=True, split=\"train\")\n",
    "dl = DataLoader(ds, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "batch = next(iter(dl))\n",
    "\n",
    "print(\"Images:\", batch['image'].shape)\n",
    "\n",
    "MAG_DICT = {\n",
    "    \"20x\": 0,\n",
    "    \"10x\": 1,\n",
    "    \"5x\": 2,\n",
    "    \"2_5x\": 3,\n",
    "    \"1_25x\": 4,\n",
    "}\n",
    "print(\"Magnifications:\", batch['mag'])\n",
    "print(\"SSL Features:\", batch['ssl_feat_unpooled'].shape)\n",
    "\n",
    "# =============================\n",
    "# ✅ LOAD MODEL\n",
    "# =============================\n",
    "ckpt_path = hf_hub_download(repo_id=\"StonyBrook-CVLab/ZoomLDM\", filename=\"brca/weights.ckpt\")\n",
    "state_dict = torch.load(ckpt_path, map_location=\"cpu\")  # load to CPU first\n",
    "\n",
    "config_path = hf_hub_download(repo_id=\"StonyBrook-CVLab/ZoomLDM\", filename=\"brca/config.yaml\")\n",
    "config = OmegaConf.load(config_path)\n",
    "\n",
    "with io.capture_output() as _:\n",
    "    model = instantiate_from_config(config.model)\n",
    "model = model.to(device).eval()\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "# disable null token\n",
    "model.cond_stage_model.p_uncond = 0\n",
    "\n",
    "# =============================\n",
    "# ✅ SAMPLING PARAMETERS\n",
    "# =============================\n",
    "t0 = 1000\n",
    "stride = 50\n",
    "print(\"Total steps\", t0 // stride)\n",
    "\n",
    "guidance = 2\n",
    "batch_size = 16  # reduce if GPU memory is limited\n",
    "\n",
    "# consistency between scales\n",
    "h = 0.005\n",
    "lr = 0.5\n",
    "\n",
    "# number of steps\n",
    "n_steps = 10\n",
    "\n",
    "# =============================\n",
    "# ✅ PREPARE FEATURES\n",
    "# =============================\n",
    "ssl_feat = batch['ssl_feat_unpooled'][0].float().to(device)\n",
    "\n",
    "if MAG == \"10x\":\n",
    "    emb_h, emb_w = 2, 2\n",
    "elif MAG == \"5x\":\n",
    "    emb_h, emb_w = 4, 4\n",
    "elif MAG == \"2_5x\":\n",
    "    emb_h, emb_w = 8, 8\n",
    "elif MAG == \"1_25x\":\n",
    "    emb_h, emb_w = 16, 16\n",
    "\n",
    "with torch.no_grad():\n",
    "    ssl_feat_20x = rearrange(ssl_feat, \"d (p1 h) (p2 w) -> (p1 p2) d h w\", p1=emb_h, p2=emb_w)\n",
    "    cond_dict_20x = dict(\n",
    "        ssl_feat=[ssl_feat_20x[i] for i in range(ssl_feat_20x.shape[0])],\n",
    "        mag=torch.tensor([MAG_DICT[\"20x\"]]).long().tile(ssl_feat_20x.shape[0]).to(device)\n",
    "    )\n",
    "    cond_20x_all = model.get_learned_conditioning(cond_dict_20x)\n",
    "\n",
    "    if emb_h > 8 and emb_w > 8:\n",
    "        ssl_feat_guide = F.adaptive_avg_pool2d(ssl_feat.unsqueeze(0), (8, 8))\n",
    "    else:\n",
    "        ssl_feat_guide = ssl_feat.unsqueeze(0)\n",
    "\n",
    "    cond_dict_guide = dict(\n",
    "        ssl_feat=[ssl_feat_guide[i] for i in range(ssl_feat_guide.shape[0])],\n",
    "        mag=torch.tensor([MAG_DICT[MAG]]).long().tile(ssl_feat_guide.shape[0]).to(device)\n",
    "    )\n",
    "    cond_guide = model.get_learned_conditioning(cond_dict_guide)\n",
    "\n",
    "# =============================\n",
    "# ✅ RESIZERS\n",
    "# =============================\n",
    "down_operator = Resizer((1, 3, 256, 256), scale_factor=1 / emb_h).to(device)\n",
    "up_operator = Resizer((1, 3, 256 // emb_h, 256 // emb_w), scale_factor=emb_h).to(device)\n",
    "\n",
    "# =============================\n",
    "# ✅ GENERATION LOOP\n",
    "# =============================\n",
    "xt_20x_all = torch.randn((emb_h * emb_w, 3, 64, 64), device=device)\n",
    "xt_guide = torch.randn((1, 3, 64, 64), device=device)\n",
    "\n",
    "for idx, t in tqdm(enumerate(range(t0, 0, -stride)), total=t0 // stride):\n",
    "    atbar = model.alphas_cumprod[t - 1].view(1, 1, 1, 1).to(device)\n",
    "    atbar_prev = model.alphas_cumprod[max(t - 1 - stride, 0)].view(1, 1, 1, 1).to(device)\n",
    "    beta_tilde = (model.betas[t - 1] * (1 - atbar_prev) / (1 - atbar)).view(1, 1, 1, 1).to(device)\n",
    "\n",
    "    epsilon_guide = model_pred(model, xt_guide, t, cond_guide, w=guidance)\n",
    "    x0_pred_guide = xt_guide / torch.sqrt(atbar) - epsilon_guide * torch.sqrt((1 - atbar) / atbar)\n",
    "    img_pred_guide = model.decode_first_stage(x0_pred_guide).clamp(-1, 1)\n",
    "\n",
    "    x0_pred_20x_all = []\n",
    "    eps_20x_all = []\n",
    "    for idx_20x in range(0, xt_20x_all.shape[0], batch_size):\n",
    "        xt_20x = xt_20x_all[idx_20x:idx_20x + batch_size, ...]\n",
    "        cond_20x = cond_20x_all[idx_20x:idx_20x + batch_size, ...]\n",
    "        img_patches_guide = rearrange(img_pred_guide, \"b c (p1 h) (p2 w) -> (b p1 p2) c h w\",\n",
    "                                      p1=emb_h, p2=emb_w)[idx_20x:idx_20x + batch_size, ...]\n",
    "\n",
    "        epsilon_20x = model_pred(model, xt_20x, t, cond_20x, w=guidance)\n",
    "        x0_pred_20x = xt_20x / torch.sqrt(atbar) - epsilon_20x * torch.sqrt((1 - atbar) / atbar)\n",
    "\n",
    "        for k in range(n_steps):\n",
    "            img_pred = model.decode_first_stage(x0_pred_20x)\n",
    "            z = model.get_first_stage_encoding(model.encode_first_stage(img_pred))\n",
    "\n",
    "            img_error_dir = up_operator(img_patches_guide - down_operator(img_pred))\n",
    "            img_error_dir = img_error_dir / img_error_dir.abs().reshape(xt_20x.shape[0], -1).max(1)[0].view(-1, 1, 1, 1)\n",
    "\n",
    "            z_perturbed = model.get_first_stage_encoding(model.encode_first_stage(img_pred + h * img_error_dir))\n",
    "            error_dir = (z_perturbed - z)\n",
    "            error_dir = error_dir / error_dir.abs().reshape(xt_20x.shape[0], -1).max(1)[0].view(-1, 1, 1, 1)\n",
    "\n",
    "            xt_error_dir = xt_20x + h * error_dir\n",
    "            epsilon_error_dir = model_pred(model, xt_error_dir, t, cond_20x, w=guidance)\n",
    "            x0_pred_error_dir = xt_error_dir / torch.sqrt(atbar) - epsilon_error_dir * torch.sqrt((1 - atbar) / atbar)\n",
    "            grad = (x0_pred_error_dir - x0_pred_20x) / h\n",
    "\n",
    "            max_grad = grad.abs().reshape(xt_20x.shape[0], -1).max(1)[0].view(-1, 1, 1, 1)\n",
    "            grad = grad / max_grad\n",
    "\n",
    "            xt_20x = xt_20x + lr * grad\n",
    "            epsilon_20x = model_pred(model, xt_20x, t, cond_20x, w=guidance)\n",
    "            x0_pred_20x = xt_20x / torch.sqrt(atbar) - epsilon_20x * torch.sqrt((1 - atbar) / atbar)\n",
    "\n",
    "        x0_pred_20x_all.append(x0_pred_20x)\n",
    "        eps_20x_all.append(epsilon_20x)\n",
    "\n",
    "    x0_pred_20x_all = torch.cat(x0_pred_20x_all, dim=0)\n",
    "    eps_20x_all = torch.cat(eps_20x_all, dim=0)\n",
    "\n",
    "    xt_20x_all = torch.sqrt(atbar_prev) * x0_pred_20x_all + torch.sqrt(1 - atbar_prev) * eps_20x_all + torch.sqrt(beta_tilde) * torch.randn_like(xt_20x_all)\n",
    "    xt_guide = torch.sqrt(atbar_prev) * x0_pred_guide + torch.sqrt(1 - atbar_prev) * epsilon_guide + torch.sqrt(beta_tilde) * torch.randn_like(xt_guide)\n",
    "\n",
    "# =============================\n",
    "# ✅ VISUALIZE RESULTS\n",
    "# =============================\n",
    "image_guide = model.decode_first_stage(xt_guide)\n",
    "image_guide = (0.5 * (image_guide + 1)).clamp(0, 1).cpu().numpy().transpose([0, 2, 3, 1])\n",
    "image_guide = (255 * image_guide).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_guide[0])\n",
    "plt.title(f\"Lower magnification image at {MAG}\")\n",
    "plt.show()\n",
    "\n",
    "xt_20x = rearrange(xt_20x_all, \"(b p1 p2) c h w -> b c (p1 h) (p2 w)\", p1=emb_h, p2=emb_w)\n",
    "image_20x = decode_large_image(xt_20x, model)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_20x[0])\n",
    "plt.title(\"20x image\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(Image.fromarray(image_guide[0]).resize((1024, 1024)))\n",
    "ax[0].set_title(f\"Lower magnification image at {MAG}\")\n",
    "ax[1].imshow(Image.fromarray(image_20x[0]))\n",
    "ax[1].set_title(\"20x image\")\n",
    "plt.show()\n",
    "\n",
    "# =============================\n",
    "# ✅ POSTPROCESSING\n",
    "# =============================\n",
    "t0 = 300\n",
    "stride = 50\n",
    "guidance = 2\n",
    "\n",
    "ssl_feat = batch['ssl_feat_unpooled'][0].float().to(device)\n",
    "xt_20x_all_postprocessed = postprocess_image(\n",
    "    model, xt_20x_all, ssl_feat,\n",
    "    t0, stride, guidance,\n",
    "    sliding_window_size=16, emb_h=emb_h, emb_w=emb_w, batch_size=16\n",
    ")\n",
    "\n",
    "xt_20x_postprocessed = rearrange(xt_20x_all_postprocessed, \"(b p1 p2) c h w -> b c (p1 h) (p2 w)\", p1=emb_h, p2=emb_w)\n",
    "image_20x_postprocessed = decode_large_image(xt_20x_postprocessed, model)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(Image.fromarray(image_guide[0]).resize((1024, 1024)))\n",
    "ax[0].set_title(f\"Lower magnification image at {MAG}\")\n",
    "ax[1].imshow(Image.fromarray(image_20x_postprocessed[0]))\n",
    "ax[1].set_title(\"20x image - postprocessed\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
